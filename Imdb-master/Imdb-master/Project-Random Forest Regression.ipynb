{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of csv file\n",
    "%fs ls  /FileStore/tables/movie_metadata1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql DROP TABLE IF EXISTS movie_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CREATE TABLE movie_metadata (\n",
    "  color STRING,\n",
    "  director_name STRING,\n",
    "  num_critic_for_reviews DOUBLE,\n",
    "  duration DOUBLE,\n",
    "  director_facebook_likes DOUBLE,\n",
    "  actor_3_facebook_likes DOUBLE,\n",
    "  actor_2_name DOUBLE,\n",
    "  actor_1_facebook_likes DOUBLE,\n",
    "  gross DOUBLE,\n",
    "  genres STRING,\n",
    "  actor_1_name STRING,\n",
    "  movie_title STRING,\n",
    "  num_voted_users DOUBLE,\n",
    "  cast_total_facebook_likes DOUBLE,\n",
    "  actor_3_name STRING,\n",
    "  facenumber_in_poster DOUBLE,\n",
    "  plot_keywords STRING,\n",
    "  movie_imdb_link STRING,\n",
    "  num_user_for_reviews DOUBLE,\n",
    "  language STRING,\n",
    "  country STRING,\n",
    "  content_rating STRING,\n",
    "  budget DOUBLE,\n",
    "  title_year DOUBLE,\n",
    "  actor_2_facebook_likes DOUBLE,\n",
    "  imdb_score DOUBLE,\n",
    "  aspect_ratio DOUBLE,\n",
    "  movie_facebook_likes DOUBLE\n",
    "  )\n",
    "  \n",
    "USING com.databricks.spark.csv\n",
    "OPTIONS (path \"/FileStore/tables/movie_metadata.csv\", header \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dataset\n",
    "dataset = spark.table(\"movie_metadata\")\n",
    "cols = dataset.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null values\n",
    "df=dataset.drop( 'color' ,\n",
    "  'director_name' ,\n",
    "  'num_critic_for_reviews' ,\n",
    "  \n",
    "  \n",
    "  \n",
    "  'actor_2_name' ,\n",
    "  \n",
    "  'gross' ,\n",
    "  'genres' ,\n",
    "  'actor_1_name' ,\n",
    "  'movie_title' ,\n",
    "  'num_voted_users' ,\n",
    "  'cast_total_facebook_likes' ,\n",
    "  'actor_3_name' ,\n",
    "  \n",
    "  'plot_keywords' ,\n",
    "  'movie_imdb_link' ,\n",
    "  'num_user_for_reviews' ,\n",
    "  'language' ,\n",
    "  'country' ,\n",
    "  'content_rating' ,\n",
    "  \n",
    "  'title_year' ,\n",
    "  \n",
    "   \n",
    "  'aspect_ratio' ,\n",
    "  'movie_facebook_likes' )\n",
    "df = df.na.drop()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col  # for indicating a column using a string in the line below\n",
    "df = df.select([col(c).cast(\"double\").alias(c) for c in df.columns])\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featuresCols = df.columns\n",
    "featuresCols.remove('imdb_score')\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=featuresCols,\n",
    "    outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=[assembler]) # ref[1]\n",
    "# Run the feature transformations.\n",
    "#  - fit() computes feature statistics as needed.\n",
    "#  - transform() actually transforms the features.\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedcols = [\"imdb_score\", \"features\"]\n",
    "df = df.select(selectedcols)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData, testData = df.randomSplit([0.8, 0.2])\n",
    "print trainingData.count()\n",
    "print testData.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Create an initial RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"imdb_score\", featuresCol=\"features\")\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the Transformer.transform() method.\n",
    "predictions = rfModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"imdb_score\", \"prediction\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=rf.getLabelCol(), predictionCol=rf.getPredictionCol())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [2, 4, 6])\n",
    "             .addGrid(rf.maxBins, [20, 60])\n",
    "             .addGrid(rf.numTrees, [5, 20])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, evaluator=evaluator, estimatorParamMaps=paramGrid, numFolds=5) # ref[2]\n",
    "\n",
    "cvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Best model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"imdb_score\", \"prediction\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for entire dataset\n",
    "finalPredictions = bestModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref[1]:https://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline\n",
    "ref[2]:https://spark.apache.org/docs/latest/ml-tuning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text in the document by Neha Gaikwad and Nupur Deshpande is licensed under CC BY 3.0 https://creativecommons.org/licenses/by/3.0/us/\n",
    "The code in the document by Neha Gaikwad and Nupur Deshpande is licensed under the MIT License https://opensource.org/licenses/MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "Project",
  "notebookId": 1968510312413274
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
